{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6282ee3",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc6fad",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.7\n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0a0be",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fb0669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97237d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64221b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9111</th>\n",
       "      <td>9124</td>\n",
       "      <td>\"\\nSorry not to see you at the session; the lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79679</th>\n",
       "      <td>79755</td>\n",
       "      <td>\"\\nNPOV editing\\nI'm sorry i was about to put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125367</th>\n",
       "      <td>125496</td>\n",
       "      <td>\"\\n\\n Jaitapur Nuclear Power Project \\nHi Yoni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32045</th>\n",
       "      <td>32085</td>\n",
       "      <td>If you're allowed to remove prods... \\n\\n...wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85034</th>\n",
       "      <td>85115</td>\n",
       "      <td>Please do not remove discussion posts \\n\\nThis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117196</th>\n",
       "      <td>117295</td>\n",
       "      <td>\"Leslie Stefanson==\\nYou'll notice the link to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44805</th>\n",
       "      <td>44858</td>\n",
       "      <td>\"\\n\\nWith all due respect, your comments about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142511</th>\n",
       "      <td>142664</td>\n",
       "      <td>I fail to understand why people immediatly jum...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80042</th>\n",
       "      <td>80118</td>\n",
       "      <td>\"\\n\\nWhy don't we try to resolve this issue on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116345</th>\n",
       "      <td>116444</td>\n",
       "      <td>Accept my apology! \\n\\nAccept my apology THIS ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "9111          9124  \"\\nSorry not to see you at the session; the lo...      0\n",
       "79679        79755  \"\\nNPOV editing\\nI'm sorry i was about to put ...      0\n",
       "125367      125496  \"\\n\\n Jaitapur Nuclear Power Project \\nHi Yoni...      0\n",
       "32045        32085  If you're allowed to remove prods... \\n\\n...wh...      0\n",
       "85034        85115  Please do not remove discussion posts \\n\\nThis...      0\n",
       "117196      117295  \"Leslie Stefanson==\\nYou'll notice the link to...      0\n",
       "44805        44858  \"\\n\\nWith all due respect, your comments about...      0\n",
       "142511      142664  I fail to understand why people immediatly jum...      0\n",
       "80042        80118  \"\\n\\nWhy don't we try to resolve this issue on...      0\n",
       "116345      116444  Accept my apology! \\n\\nAccept my apology THIS ...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c41f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9488b091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b8e99",
   "metadata": {},
   "source": [
    "Посмотрим на баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4138ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71922cec",
   "metadata": {},
   "source": [
    "Классы явно несбалансированы. Это необходимо учесть при обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bef3d26",
   "metadata": {},
   "source": [
    "В нашем распоряжении датасет, состоящий из 2 столбцов и 159571 строки. В столбце text находится текст комментария, в столбце toxic — целевой признак. Дубликатов нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de107fdd",
   "metadata": {},
   "source": [
    "**Проведем предобработку текстовых данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205ae1e",
   "metadata": {},
   "source": [
    "Создадим корпус постов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0648657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f58d45",
   "metadata": {},
   "source": [
    "Проведем лемматизацию текста и очистим текст лишних символов с помощью регулярных выражений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f21aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "def clear_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemm_text = ' '.join([token.lemma_ for token in doc])\n",
    "    clear_text = re.sub(r'[^a-zA-Z]', ' ', lemm_text) \n",
    "    return ' '.join(clear_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb514ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 159292/159292 [16:51<00:00, 157.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(corpus))):\n",
    "    corpus[i] = clear_text(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6784351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>d aww he match this background colour I be see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hey man I be really not try to edit war it be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>More I can not make any real suggestion on imp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>congratulation from I as well use the tool wel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER before you pis around on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>sorry if the word nonsense be offensive to you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which be contrar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  explanation why the edit make under my usernam...      0\n",
       "1           1  d aww he match this background colour I be see...      0\n",
       "2           2  hey man I be really not try to edit war it be ...      0\n",
       "3           3  More I can not make any real suggestion on imp...      0\n",
       "4           4  you sir be my hero any chance you remember wha...      0\n",
       "5           5  congratulation from I as well use the tool wel...      0\n",
       "6           6        COCKSUCKER before you pis around on my work      1\n",
       "7           7  your vandalism to the Matt Shirvington article...      0\n",
       "8           8  sorry if the word nonsense be offensive to you...      0\n",
       "9           9  alignment on this subject and which be contrar...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c70c5",
   "metadata": {},
   "source": [
    "Разделим данные на выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21138d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['text']\n",
    "target = data['toxic']\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.20, random_state=111, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d47c619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127433,)\n",
      "(31859,)\n",
      "(127433,)\n",
      "(31859,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99030d15",
   "metadata": {},
   "source": [
    "Рассчитаем TF-IDF, указав стоп-слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dae0bcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anastasia/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords') \n",
    "stopwords = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ce8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords, max_features=50000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e26dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = count_tf_idf.fit_transform(features_train) \n",
    "tf_idf_test = count_tf_idf.transform(features_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4995e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127433, 50000)\n",
      "(31859, 50000)\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_train.shape)\n",
    "print(tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6be33f",
   "metadata": {},
   "source": [
    "Данные разделены на выборки, признаки получены из TF-IDF. Можно приступать к обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7941079",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a84d24b",
   "metadata": {},
   "source": [
    "Обучим 2 модели: LogisticRegression и RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27084c16",
   "metadata": {},
   "source": [
    "**1) LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "774da85a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasia/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/anastasia/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/anastasia/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/anastasia/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.9000000000000001, 'solver': 'lbfgs'} F1 LogisticRegression 0.7456337493935784\n",
      "CPU times: user 11.6 s, sys: 3.73 s, total: 15.3 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', random_state=222)\n",
    "parameters = {\n",
    "    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'C': np.arange(0.1, 1, 0.2)\n",
    "}\n",
    "CV_lr = GridSearchCV(estimator=lr, param_grid=parameters, n_jobs=-1, verbose=3, cv=3, scoring='f1')\n",
    "CV_lr.fit(tf_idf_train, target_train)\n",
    "CV_lr_best_par = CV_lr.best_params_\n",
    "CV_lr_best_score = CV_lr.best_score_\n",
    "print(CV_lr_best_par, 'F1 LogisticRegression', CV_lr_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd660acf",
   "metadata": {},
   "source": [
    "Проверим качество модели на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00e3697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 3.03 s, total: 14.3 s\n",
      "Wall time: 2.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.9, class_weight='balanced', random_state=222)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', random_state=222, solver='lbfgs', C=0.9)\n",
    "lr.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "526b3874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 LogisticRegression на тестовой выборке: 0.7340354619384083\n",
      "CPU times: user 118 ms, sys: 71 ms, total: 189 ms\n",
      "Wall time: 40.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_predictions = lr.predict(tf_idf_test)\n",
    "print('F1 LogisticRegression на тестовой выборке:', f1_score(target_test, lr_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f6db3",
   "metadata": {},
   "source": [
    "На тестовой выборке модель LogisticRegression показала метрику качества F1 = 0.73."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c60075",
   "metadata": {},
   "source": [
    "**2) RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f1fc294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "{'max_depth': 16, 'n_estimators': 150} F1 RandomForestRegressor 0.4134785202371685\n",
      "CPU times: user 7.12 s, sys: 645 ms, total: 7.77 s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=12345)\n",
    "parameters = {\n",
    "    'n_estimators': list(range(50, 200, 50)),\n",
    "    'max_depth': list(range(1, 20, 5))\n",
    "}\n",
    "CV_rf = GridSearchCV(estimator=rf, param_grid=parameters, n_jobs=-1, verbose=3, cv=3, scoring='f1')\n",
    "CV_rf.fit(tf_idf_train, target_train)\n",
    "CV_rf_best_par = CV_rf.best_params_\n",
    "CV_rf_best_score = CV_rf.best_score_\n",
    "print(CV_rf_best_par, 'F1 RandomForestRegressor', CV_rf_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8117b4d",
   "metadata": {},
   "source": [
    "Проверим качество модели на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70f54a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.22 s, sys: 33.6 ms, total: 4.25 s\n",
      "Wall time: 4.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=16,\n",
       "                       random_state=12345)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=12345, max_depth=16, n_estimators=100)\n",
    "rf.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e9630fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 RandomForest на тестовой выборке: 0.40374470614458724\n",
      "CPU times: user 285 ms, sys: 9.44 ms, total: 294 ms\n",
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_predictions = rf.predict(tf_idf_test)\n",
    "print('F1 RandomForest на тестовой выборке:', f1_score(target_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86971dfd",
   "metadata": {},
   "source": [
    "На тестовой выборке модель RandomForest показала метрику качества F1 = 0.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87c673",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d4f20",
   "metadata": {},
   "source": [
    "На первом этапе работы была произведена загрузка данных и их подготовка для дальнейшего обучения моделей. Тексты были очищены, лемматизированы и векторизированы. \n",
    "\n",
    "Далее были обучены 2 модели: логистическая регрессия и случайный лес. Наилучшую метрику качества F1 показала модель логистической регрессии (F1=0.73). Цель работы достигнута."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
